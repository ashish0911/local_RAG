# Local RAG

A lightweight, fully local Retrieval Augmented Generation (RAG) system that runs entirely on your machine. No cloud services, no API keys, just your data and your compute.

## What is Local RAG?

Local RAG is a privacy-focused implementation of the Retrieval Augmented Generation pattern. It enables you to:

- Run an LLM (Large Language Model) on your local machine
- Create and manage vector embeddings for your documents locally
- Search and retrieve relevant context from your personal knowledge base
- Generate responses augmented with your retrieved data
- Maintain complete privacy with no data leaving your machine

This project combines the power of modern LLMs with the flexibility of vector databases while respecting user privacy and maintaining data sovereignty.

## Current Status

- Loading model using ollama